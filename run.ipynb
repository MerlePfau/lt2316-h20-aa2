{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa1 stuff\n",
    "from aa1 import DataLoader\n",
    "from aa1 import extract_features\n",
    "from aa1 import check_output\n",
    "\n",
    "from aa2 import Trainer\n",
    "from aa2 import parallel_coordinates\n",
    "from aa2.model import LSTM_fixed_len as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigment 1 stuff\n",
    "dataset = DataLoader(data_dir=\"../../DDICorpus/DDICorpus/\", device=device)\n",
    "train_y, val_y, test_y = check_output(dataset.get_y()) \n",
    "train_X, val_X, test_X = check_output(extract_features(\n",
    "                                                        data=dataset.data_df,\n",
    "                                                        max_sample_length=dataset.max_sample_length,\n",
    "                                                        id2word=dataset.id2word,\n",
    "                                                        device=device\n",
    "                                                        #Add any addtional arguments here\n",
    "                                                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up trainer\n",
    "model_dump = \"/tmp/aa2_models/\" #you are allowed to change the dump_folder\n",
    "trainer = Trainer(dump_folder=model_dump) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a set of hyperparamaters\n",
    "# test at least 5 different sets of hyperparamaters \n",
    "set_hyperparamaters = [{\"learning_rate\": 0.001,\n",
    "                        \"hidden_size\": 1000,\n",
    "                        \"number_layers\": 3,\n",
    "                        \"optimizer\": \"adam\",\n",
    "                        \"batch_size\": 25,\n",
    "                        \"bidirectional\": 1\n",
    "                       },\n",
    "                       {\"learning_rate\": 0.02,\n",
    "                        \"hidden_size\": 100,\n",
    "                        \"number_layers\": 5,\n",
    "                        \"optimizer\": \"SGD\",\n",
    "                        \"batch_size\": 50,\n",
    "                        \"bidirectional\": 1\n",
    "                       },\n",
    "                       {\"learning_rate\": 0.2,\n",
    "                        \"hidden_size\": 10,\n",
    "                        \"number_layers\": 10,\n",
    "                        \"optimizer\": \"SGD\",\n",
    "                        \"batch_size\": 5,\n",
    "                        \"bidirectional\": 1\n",
    "                       },\n",
    "                       {\"learning_rate\": 0.001,\n",
    "                        \"hidden_size\": 1000,\n",
    "                        \"number_layers\": 64,\n",
    "                        \"optimizer\": \"SGD\",\n",
    "                        \"batch_size\": 100,\n",
    "                        \"bidirectional\": 1\n",
    "                       },\n",
    "                       {\"learning_rate\": 0.02,\n",
    "                        \"hidden_size\": 150,\n",
    "                        \"number_layers\": 32,\n",
    "                        \"optimizer\": \"adam\",\n",
    "                        \"batch_size\": 10,\n",
    "                        \"bidirectional\": 1\n",
    "                       }\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([25, 103])) that is different to the input size (torch.Size([3, 25, 103])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([16, 103])) that is different to the input size (torch.Size([3, 16, 103])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 124.906982421875.\n",
      "Total loss in epoch 1 is 93.2801742553711.\n",
      "Total loss in epoch 2 is 93.39066314697266.\n",
      "Total loss in epoch 3 is 92.33031463623047.\n",
      "Total loss in epoch 4 is 91.89219665527344.\n",
      "Total loss in epoch 5 is 77.38965606689453.\n",
      "Total loss in epoch 6 is 62.51066207885742.\n",
      "Total loss in epoch 7 is 49.679317474365234.\n",
      "Total loss in epoch 8 is 44.05645751953125.\n",
      "Total loss in epoch 9 is 41.426143646240234.\n",
      "Total loss in epoch 10 is 39.063045501708984.\n",
      "Total loss in epoch 11 is 37.356170654296875.\n",
      "Total loss in epoch 12 is 35.96910095214844.\n",
      "Total loss in epoch 13 is 34.82511901855469.\n",
      "Total loss in epoch 14 is 34.51583480834961.\n",
      "Total loss in epoch 15 is 33.36958694458008.\n",
      "Total loss in epoch 16 is 32.542415618896484.\n",
      "Total loss in epoch 17 is 31.80033302307129.\n",
      "Total loss in epoch 18 is 31.40809440612793.\n",
      "Total loss in epoch 19 is 31.250656127929688.\n",
      "Total loss in epoch 20 is 29.838499069213867.\n",
      "Total loss in epoch 21 is 29.216331481933594.\n",
      "Total loss in epoch 22 is 28.688217163085938.\n",
      "Total loss in epoch 23 is 28.26287078857422.\n",
      "Total loss in epoch 24 is 27.81991195678711.\n",
      "Total loss in epoch 25 is 27.505308151245117.\n",
      "Total loss in epoch 26 is 26.984764099121094.\n",
      "Total loss in epoch 27 is 26.48299789428711.\n",
      "Total loss in epoch 28 is 26.22458267211914.\n",
      "Total loss in epoch 29 is 26.088119506835938.\n",
      "Total loss in epoch 30 is 25.720462799072266.\n",
      "Total loss in epoch 31 is 25.36851692199707.\n",
      "Total loss in epoch 32 is 25.112733840942383.\n",
      "Total loss in epoch 33 is 25.293346405029297.\n",
      "Total loss in epoch 34 is 24.766164779663086.\n",
      "Total loss in epoch 35 is 24.14080238342285.\n",
      "Total loss in epoch 36 is 24.057235717773438.\n",
      "Total loss in epoch 37 is 23.53800392150879.\n",
      "Total loss in epoch 38 is 23.192913055419922.\n",
      "Total loss in epoch 39 is 22.70427894592285.\n",
      "Total loss in epoch 40 is 22.6287784576416.\n",
      "Total loss in epoch 41 is 22.365524291992188.\n",
      "Total loss in epoch 42 is 22.119291305541992.\n",
      "Total loss in epoch 43 is 22.081817626953125.\n",
      "Total loss in epoch 44 is 21.63189125061035.\n",
      "Total loss in epoch 45 is 21.3290958404541.\n",
      "Total loss in epoch 46 is 22.456148147583008.\n",
      "Total loss in epoch 47 is 21.001445770263672.\n",
      "Total loss in epoch 48 is 20.80600929260254.\n",
      "Total loss in epoch 49 is 20.723737716674805.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([50, 103])) that is different to the input size (torch.Size([5, 50, 103])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([41, 103])) that is different to the input size (torch.Size([5, 41, 103])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 416.87493896484375.\n",
      "Total loss in epoch 1 is 415.2378845214844.\n",
      "Total loss in epoch 2 is 413.7034606933594.\n",
      "Total loss in epoch 3 is 412.24969482421875.\n",
      "Total loss in epoch 4 is 410.7257080078125.\n",
      "Total loss in epoch 5 is 409.2521667480469.\n",
      "Total loss in epoch 6 is 407.719970703125.\n",
      "Total loss in epoch 7 is 406.21783447265625.\n",
      "Total loss in epoch 8 is 404.6769714355469.\n",
      "Total loss in epoch 9 is 403.137939453125.\n",
      "Total loss in epoch 10 is 401.53790283203125.\n",
      "Total loss in epoch 11 is 399.9736633300781.\n",
      "Total loss in epoch 12 is 398.4175109863281.\n",
      "Total loss in epoch 13 is 396.78057861328125.\n",
      "Total loss in epoch 14 is 395.1409912109375.\n",
      "Total loss in epoch 15 is 393.4272766113281.\n",
      "Total loss in epoch 16 is 391.7060241699219.\n",
      "Total loss in epoch 17 is 389.9023132324219.\n",
      "Total loss in epoch 18 is 388.0305480957031.\n",
      "Total loss in epoch 19 is 386.0952453613281.\n",
      "Total loss in epoch 20 is 384.0383605957031.\n",
      "Total loss in epoch 21 is 381.84173583984375.\n",
      "Total loss in epoch 22 is 379.3954772949219.\n",
      "Total loss in epoch 23 is 376.71319580078125.\n",
      "Total loss in epoch 24 is 373.5862121582031.\n",
      "Total loss in epoch 25 is 369.7322692871094.\n",
      "Total loss in epoch 26 is 364.5863342285156.\n",
      "Total loss in epoch 27 is 356.4427795410156.\n",
      "Total loss in epoch 28 is 339.99517822265625.\n",
      "Total loss in epoch 29 is 300.29351806640625.\n",
      "Total loss in epoch 30 is 209.87266540527344.\n",
      "Total loss in epoch 31 is 112.70942687988281.\n",
      "Total loss in epoch 32 is 80.98428344726562.\n",
      "Total loss in epoch 33 is 59.963687896728516.\n",
      "Total loss in epoch 34 is 47.049407958984375.\n",
      "Total loss in epoch 35 is 45.6129035949707.\n",
      "Total loss in epoch 36 is 45.01158905029297.\n",
      "Total loss in epoch 37 is 44.708892822265625.\n",
      "Total loss in epoch 38 is 44.4703369140625.\n",
      "Total loss in epoch 39 is 44.36200714111328.\n",
      "Total loss in epoch 40 is 44.23988723754883.\n",
      "Total loss in epoch 41 is 44.096336364746094.\n",
      "Total loss in epoch 42 is 44.03022003173828.\n",
      "Total loss in epoch 43 is 43.972015380859375.\n",
      "Total loss in epoch 44 is 43.92919158935547.\n",
      "Total loss in epoch 45 is 43.866188049316406.\n",
      "Total loss in epoch 46 is 43.84368133544922.\n",
      "Total loss in epoch 47 is 43.79492950439453.\n",
      "Total loss in epoch 48 is 43.775779724121094.\n",
      "Total loss in epoch 49 is 43.739776611328125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([5, 103])) that is different to the input size (torch.Size([10, 5, 103])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/usr/local/lib64/python3.7/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([1, 103])) that is different to the input size (torch.Size([10, 1, 103])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 2011.013671875.\n",
      "Total loss in epoch 1 is 487.0938720703125.\n",
      "Total loss in epoch 2 is 474.1143493652344.\n",
      "Total loss in epoch 3 is 467.48504638671875.\n",
      "Total loss in epoch 4 is 462.4220886230469.\n"
     ]
    }
   ],
   "source": [
    "# hyperparamater tuning\n",
    "# train you model with your set of hyperparamaters\n",
    "for hp in set_hyperparamaters:\n",
    "    trainer.train(train_X, train_y, val_X, val_y, model, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a parallel coordination plot over hyperparamaters\n",
    "# add path to models and change metric to what ever metric you have chosen to use/want to use\n",
    "parallel_coordinates(model_dump, metric=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the Parallel Coordination plot define 3 new hyperparamaters set thay you \n",
    "# think are worth testing\n",
    "set_hyperparamaters_2 = [\n",
    "                        # Example:\n",
    "                        # {\n",
    "                        #   \"learning_rate\": 0.1,\n",
    "                        #   \"number_layers\": 3,\n",
    "                        #   \"optimizer\": \"adam\"\n",
    "                        # }\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models for the new hyperparamaters\n",
    "for hp in set_hyperparamaters_2:\n",
    "    trainer.train(train_X, train_y, val_X, val_y, YOUR_MODEL_CLASS, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a parallel coordination plot over hyperparamaters again\n",
    "parallel_coordinates(model_dump, metric=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the best model base on the last parallel coordination plot\n",
    "best_model_path = \"PATH TO THE BEST MODEL\"\n",
    "scores = trainer.test(test_X, test_y, YOUR_MODEL_CLASS, best_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
